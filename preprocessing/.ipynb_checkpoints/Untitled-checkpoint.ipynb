{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe6294e",
   "metadata": {},
   "source": [
    "# Design and development of an IoT-based data collection/data analysis system\n",
    "\n",
    "#### by MÃ¡rk Kereszty\n",
    "\n",
    "## Data Preprocessing for ML, Classification, etc.\n",
    "\n",
    "*Note: This Jupyter Notebook is optimised for the data types in the mentioned thesis project!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e54dd",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "First lets select the data you want to process. This should be a file with *.csv* extension, downloaded from the database via the [OpenDAQ dashboard]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ecaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "file_path = filedialog.askopenfilename()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4d102",
   "metadata": {},
   "source": [
    "Now that you have selected the source, the next step is to load it into [Pandas](https://pandas.pydata.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2100973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Loaded {len(df.index)} records across {len(df['variable'].unique())} variables.\")\n",
    "print(df[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607eef9",
   "metadata": {},
   "source": [
    "### Restructuring the Data\n",
    "\n",
    "Since *_result, table, _measurement, aspect, org, sensor, student and topic* columns don't contain relevant information in the scope of ML, we can drop them.\n",
    "Notice that the *variable* column contains categorical data instead of numeric. This is not optimal for the models we want to train, but there is an easy fix for this issue. We can use a method called One_Hot Encoding: simply put, we create additional columns with the name of each variable and put a 0 or 1 in the cells, marking the variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc8a77",
   "metadata": {},
   "source": [
    "### Fixing Timestamps\n",
    "\n",
    "InfluxDB and Telegraf use *UTC* timestamps, but Hungary is in the *UTC+2* time zone. Because of the structure of the backend we know that the following variables were submited by Telegraf:\n",
    "**rpm, tempC, cur, vibX, vibY, vibZ**\n",
    "\n",
    "If the backend was modified to only use the *analytics_backend.py* script to upload measurement data to the database, then this section can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d07b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ccc857",
   "metadata": {},
   "source": [
    "### Strings to Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9786e0",
   "metadata": {},
   "source": [
    "### Dealing With Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef04be",
   "metadata": {},
   "source": [
    "### Insight (Visual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
